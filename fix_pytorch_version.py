#!/usr/bin/env python3
"""
PyTorch ç‰ˆæœ¬é—®é¢˜ä¿®å¤è„šæœ¬
è§£å†³ torch.load å®‰å…¨é—®é¢˜å’Œç‰ˆæœ¬å…¼å®¹æ€§
"""

import os
import sys
import subprocess
import importlib

def check_pytorch_version():
    """æ£€æŸ¥ PyTorch ç‰ˆæœ¬"""
    print("ğŸ” Checking PyTorch version...")
    
    try:
        import torch
        version = torch.__version__
        print(f"Current PyTorch version: {version}")
        
        # è§£æç‰ˆæœ¬å·
        major, minor = map(int, version.split('.')[:2])
        
        if major > 2 or (major == 2 and minor >= 6):
            print("âœ… PyTorch version is compatible (>= 2.6)")
            return True, version
        else:
            print(f"âš ï¸  PyTorch version {version} is too old (requires >= 2.6)")
            return False, version
            
    except ImportError:
        print("âŒ PyTorch is not installed")
        return False, None

def check_safetensors():
    """æ£€æŸ¥ safetensors æ˜¯å¦å¯ç”¨"""
    print("\nğŸ” Checking safetensors...")
    
    try:
        import safetensors
        version = safetensors.__version__
        print(f"âœ… safetensors is available: {version}")
        return True, version
    except ImportError:
        print("âš ï¸  safetensors is not installed")
        return False, None

def check_transformers():
    """æ£€æŸ¥ transformers ç‰ˆæœ¬"""
    print("\nğŸ” Checking transformers...")
    
    try:
        import transformers
        version = transformers.__version__
        print(f"Current transformers version: {version}")
        return True, version
    except ImportError:
        print("âŒ transformers is not installed")
        return False, None

def install_safetensors():
    """å®‰è£… safetensors"""
    print("\nğŸ“¦ Installing safetensors...")
    
    try:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", "safetensors"
        ])
        print("âœ… safetensors installed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ Failed to install safetensors: {e}")
        return False

def create_pytorch_workaround():
    """åˆ›å»º PyTorch å…¼å®¹æ€§è§£å†³æ–¹æ¡ˆ"""
    print("\nğŸ› ï¸  Creating PyTorch compatibility workaround...")
    
    workaround_code = '''
"""
PyTorch å…¼å®¹æ€§è§£å†³æ–¹æ¡ˆ
è§£å†³ torch.load å®‰å…¨é—®é¢˜
"""

import torch
import warnings
import os

# ä¿å­˜åŸå§‹çš„ torch.load å‡½æ•°
_original_torch_load = torch.load

def safe_torch_load(f, map_location=None, pickle_module=None, weights_only=None, **kwargs):
    """
    å®‰å…¨çš„ torch.load åŒ…è£…å™¨
    """
    try:
        # å°è¯•ä½¿ç”¨ weights_only=True
        if weights_only is None:
            weights_only = True
        
        return _original_torch_load(
            f, 
            map_location=map_location, 
            pickle_module=pickle_module,
            weights_only=weights_only,
            **kwargs
        )
    except Exception as e:
        if "weights_only" in str(e) or "CVE-2025-32434" in str(e):
            warnings.warn(
                "Using torch.load without weights_only=True due to version compatibility. "
                "Consider upgrading PyTorch to >= 2.6 for better security.",
                UserWarning
            )
            # å›é€€åˆ°ä¸ä½¿ç”¨ weights_only çš„ç‰ˆæœ¬
            kwargs.pop('weights_only', None)
            return _original_torch_load(
                f,
                map_location=map_location,
                pickle_module=pickle_module,
                **kwargs
            )
        else:
            raise e

# æ›¿æ¢ torch.load
torch.load = safe_torch_load

print("âœ… PyTorch compatibility workaround applied")
'''
    
    workaround_path = "pytorch_workaround.py"
    with open(workaround_path, 'w', encoding='utf-8') as f:
        f.write(workaround_code)
    
    print(f"âœ… Workaround created: {workaround_path}")
    return workaround_path

def test_torch_load():
    """æµ‹è¯• torch.load åŠŸèƒ½"""
    print("\nğŸ§ª Testing torch.load functionality...")
    
    try:
        import torch
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å¼ é‡
        test_tensor = torch.randn(3, 3)
        test_file = "test_tensor.pth"
        
        # ä¿å­˜å¼ é‡
        torch.save(test_tensor, test_file)
        print("âœ… torch.save works")
        
        # å°è¯•åŠ è½½å¼ é‡
        try:
            loaded_tensor = torch.load(test_file, weights_only=True)
            print("âœ… torch.load with weights_only=True works")
        except Exception as e:
            print(f"âš ï¸  torch.load with weights_only=True failed: {e}")
            try:
                loaded_tensor = torch.load(test_file)
                print("âœ… torch.load without weights_only works")
            except Exception as e2:
                print(f"âŒ torch.load failed completely: {e2}")
                return False
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_file):
            os.remove(test_file)
        
        return True
        
    except Exception as e:
        print(f"âŒ torch.load test failed: {e}")
        return False

def create_mock_clip_config():
    """åˆ›å»ºæ¨¡æ‹Ÿ CLIP é…ç½®"""
    print("\nâš™ï¸  Creating mock CLIP configuration...")
    
    mock_config = {
        'model': {
            'base_model': 'clip',
            'clip': {
                'model_name': 'openai/clip-vit-base-patch32',
                'local_model_path': 'models/pretrained/clip-vit-base-patch32',
                'freeze_backbone': False,
                'use_mock': True  # æ–°å¢ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å‹
            },
            'classifier': {
                'hidden_dims': [512, 256, 128],
                'dropout': 0.3,
                'activation': 'relu',
                'num_classes': 2
            },
            'fusion': {
                'method': 'concat',
                'fusion_dim': 512
            }
        },
        'evaluation': {
            'hallucination_types': [
                'semantic_inconsistency',
                'factual_error',
                'object_hallucination',
                'attribute_error',
                'spatial_error'
            ]
        },
        'output': {
            'results_dir': 'results/stage2'
        },
        'device': 'cpu'
    }
    
    import yaml
    config_path = "config/stage2_config_safe.yaml"
    os.makedirs(os.path.dirname(config_path), exist_ok=True)
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(mock_config, f, default_flow_style=False)
    
    print(f"âœ… Safe config created: {config_path}")
    return config_path

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("PYTORCH VERSION FIX TOOL")
    print("="*60)
    
    # æ£€æŸ¥å½“å‰çŠ¶æ€
    pytorch_ok, pytorch_version = check_pytorch_version()
    safetensors_ok, safetensors_version = check_safetensors()
    transformers_ok, transformers_version = check_transformers()
    
    print("\n" + "="*40)
    print("DIAGNOSIS SUMMARY")
    print("="*40)
    print(f"PyTorch >= 2.6: {'âœ…' if pytorch_ok else 'âŒ'}")
    print(f"safetensors: {'âœ…' if safetensors_ok else 'âŒ'}")
    print(f"transformers: {'âœ…' if transformers_ok else 'âŒ'}")
    
    # è§£å†³æ–¹æ¡ˆ
    solutions_applied = []
    
    if not safetensors_ok:
        print("\nğŸ”§ Applying solution: Install safetensors")
        if install_safetensors():
            solutions_applied.append("Installed safetensors")
            safetensors_ok = True
    
    if not pytorch_ok:
        print("\nğŸ”§ Applying solution: Create compatibility workaround")
        workaround_path = create_pytorch_workaround()
        solutions_applied.append(f"Created workaround: {workaround_path}")
    
    # åˆ›å»ºå®‰å…¨é…ç½®
    print("\nğŸ”§ Creating safe configuration")
    safe_config = create_mock_clip_config()
    solutions_applied.append(f"Created safe config: {safe_config}")
    
    # æµ‹è¯•ä¿®å¤æ•ˆæœ
    print("\nğŸ§ª Testing fixes...")
    torch_test_ok = test_torch_load()
    
    # æœ€ç»ˆæŠ¥å‘Š
    print("\n" + "="*60)
    print("FIX SUMMARY")
    print("="*60)
    
    if solutions_applied:
        print("âœ… Applied solutions:")
        for solution in solutions_applied:
            print(f"   - {solution}")
    
    print(f"\nğŸ§ª torch.load test: {'âœ… PASSED' if torch_test_ok else 'âŒ FAILED'}")
    
    if safetensors_ok and torch_test_ok:
        print("\nğŸ‰ FIXES SUCCESSFUL!")
        print("ğŸ’¡ You can now run:")
        print("   python test_stage2_simple.py")
        print("   python fix_stage2_evaluation.py")
    else:
        print("\nâš ï¸  PARTIAL SUCCESS")
        print("ğŸ’¡ Try running the simple test:")
        print("   python test_stage2_simple.py")
    
    print("="*60)

if __name__ == "__main__":
    main()
